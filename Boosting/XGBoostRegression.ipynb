{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thuật toán XGBoost for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Khởi tạo mô hình**\n",
    "- Giá trị dự đoán ban đầu thường được khởi tạo bằng giá trị trung bình của dữ liệu đầu ra.\n",
    "\n",
    "**2. Cơ sở toán học**\n",
    "- Hàm loss: $L(y, f) = \\sum_{i = 1}^N (y_i - f(x_i))^2$\n",
    "- Tuy nhiên để hạn chế overfitting, XGBoost thêm thành phần regularization: $L(y, f) = \\sum_{i = 1}^N (y_i - f(x_i))^2 + \\Omega (f)$\n",
    "    + $\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j = 1}^T w_j$.    $ \\ \\ \\ \\ \\ T$ là số nút lá\n",
    "\n",
    "- Sử dụng phép xấp xỉ Taylor đến bậc 2 thu được:\n",
    "    $$ L =  \\sum_{i=1}^{n} \\left[ g_i f(\\mathbf{x}_i) + \\frac{1}{2} h_i f^2(\\mathbf{x}_i) \\right] + \\Omega(f)$$\n",
    "\n",
    "    + $$g_i = \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} $$\n",
    "    + $$h_i = \\frac{\\partial^2 L(y_i, f(x_i))}{\\partial^2 f(x_i)} $$\n",
    "\n",
    "**3.Xây dựng M mô hình**\n",
    "- Xây dựng các cây quyết định dựa trên lỗi hiện tại\n",
    "    + Để phân chia các thuộc tính, ta sử dụng Gain. Trong XGBoost, gain được tính dựa trên đạo hàm bậc 1 (gradient), và bậc 2 (Hessian) của hàm loss \n",
    "    + Đạo hàm bậc 1: $$g_i = \\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)} $$\n",
    "    + Đạo hàm bậc 2: $$h_i = \\frac{\\partial^2 L(y_i, f(x_i))}{\\partial^2 f(x_i)} $$\n",
    "    + Tính gain: \n",
    "        $$\n",
    "        \\text{Gain} = \\frac{1}{2} \\left( \\frac{(G_l)^2}{H_l + \\lambda} + \\frac{(G_r)^2}{H_r + \\lambda} - \\frac{(G)^2}{H + \\lambda} \\right) - \\gamma\n",
    "        $$\n",
    "\n",
    "        - $G_l$ và $G_r$ là tổng gradient cho phần bên trái và phải của phân chia.\n",
    "        - $H_l$ và $H_r$ là tổng hessian cho phần bên trái và phải.\n",
    "        - $G$ và $H$ là tổng gradient và hessian trước khi chia.\n",
    "        - $\\lambda$ là tham số điều chỉnh regularization (tránh overfiting).\n",
    "        - $\\gamma$ là tham số điều chỉnh việc phân chia, có thể hiểu là nếu Gain > $\\gamma$ thì tiếp tục phân chia.\n",
    "    \n",
    "    + Cập nhật mô hình hiện tại với cây mới:\n",
    "\n",
    "        $$\n",
    "        f_{m+1}(x) = f_m(x) + \\eta \\cdot h_m(x)\n",
    "        $$\n",
    "\n",
    "        Trong đó:\n",
    "        - $\\eta$ là learning rate, điều chỉnh sự ảnh hưởng của môi hình mới đến mô hình hiện tại\n",
    "        - $h_m(x)$ là dự đoán của cây quyết định mới xây dựng dựa trên lỗi ở bên trên\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tài liệu tham khảo:\n",
    " https://arxiv.org/pdf/1603.02754"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ví dụ python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "class TreeBooster:\n",
    "    def __init__(self, X, gradients, hessians, max_depth, min_child_weight, reg_lambda, gamma, idxs=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        if idxs is None: idxs = np.arange(len(gradients))\n",
    "        self.X, self.gradients, self.hessians, self.idxs = X, gradients, hessians, idxs\n",
    "        self.n, self.c = len(idxs), X.shape[1]\n",
    "        self.value_predict = -self.gradients[self.idxs].sum() / (self.hessians[self.idxs].sum() + self.reg_lambda)\n",
    "        self.best_score_so_far = 0.\n",
    "        if self.max_depth > 0:\n",
    "            self._maybe_insert_child_nodes()\n",
    "\n",
    "    def _maybe_insert_child_nodes(self):\n",
    "        for i in range(self.c):\n",
    "            self._find_better_split(i)\n",
    "        if self.is_leaf():\n",
    "            return\n",
    "        x = self.X[self.idxs, self.split_feature_idx]\n",
    "        left_idx = self.idxs[x <= self.threshold]\n",
    "        right_idx = self.idxs[x > self.threshold]\n",
    "        self.left = TreeBooster(self.X, self.gradients, self.hessians, self.max_depth - 1, self.min_child_weight, self.reg_lambda, self.gamma, left_idx)\n",
    "        self.right = TreeBooster(self.X, self.gradients, self.hessians, self.max_depth - 1, self.min_child_weight, self.reg_lambda, self.gamma, right_idx)\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.best_score_so_far == 0.\n",
    "\n",
    "    def _find_better_split(self, feature_idx):\n",
    "        x = self.X[self.idxs, feature_idx]\n",
    "        g, h = self.gradients[self.idxs], self.hessians[self.idxs]\n",
    "        sort_idx = np.argsort(x)\n",
    "        sort_g, sort_h, sort_x = g[sort_idx], h[sort_idx], x[sort_idx]\n",
    "        sum_g, sum_h = g.sum(), h.sum()\n",
    "        sum_g_right, sum_h_right = sum_g, sum_h\n",
    "        sum_g_left, sum_h_left = 0., 0.\n",
    "\n",
    "        for i in range(0, self.n - 1):\n",
    "            g_i, h_i, x_i, x_i_next = sort_g[i], sort_h[i], sort_x[i], sort_x[i + 1]\n",
    "            sum_g_left += g_i\n",
    "            sum_h_left += h_i\n",
    "            sum_g_right -= g_i\n",
    "            sum_h_right -= h_i\n",
    "            if sum_h_left < self.min_child_weight or x_i == x_i_next:\n",
    "                continue\n",
    "            if sum_h_right < self.min_child_weight:\n",
    "                break\n",
    "\n",
    "            gain = 0.5 * ((sum_g_left**2 / (sum_h_left + self.reg_lambda))\n",
    "                          + (sum_g_right**2 / (sum_h_right + self.reg_lambda))\n",
    "                          - (sum_g**2 / (sum_h + self.reg_lambda))) - self.gamma\n",
    "\n",
    "            if gain > self.best_score_so_far:\n",
    "                self.split_feature_idx = feature_idx\n",
    "                self.best_score_so_far = gain\n",
    "                self.threshold = (x_i + x_i_next) / 2\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_row(row) for row in X])\n",
    "\n",
    "    def _predict_row(self, row):\n",
    "        if self.is_leaf():\n",
    "            return self.value_predict\n",
    "        \n",
    "        child = self.left if row[self.split_feature_idx] <= self.threshold else self.right\n",
    "        return child._predict_row(row)\n",
    "\n",
    "\n",
    "class XGBoostRegressor:\n",
    "    def __init__(self, learning_rate=0.1, max_depth=3, min_child_weight=1, gamma=0, reg_lambda=1, subsample=1.0, num_boost_round=100, random_seed=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.gamma = gamma\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.subsample = subsample\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.rng = np.random.default_rng(seed=random_seed)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_score = np.mean(y)\n",
    "        if isinstance(X, pd.DataFrame): X = X.values\n",
    "        if isinstance(y, pd.Series): y = y.values\n",
    "        current_predictions = self.base_score * np.ones_like(y)\n",
    "        self.boosters = []\n",
    "        for i in range(self.num_boost_round):\n",
    "            gradients = 2 * (current_predictions - y)\n",
    "            hessians = 2 * np.ones_like(y)\n",
    "\n",
    "            sample_idxs = None\n",
    "            \n",
    "            # Kỹ thuật subsampling\n",
    "            if self.subsample == 1.0:\n",
    "                sample_idxs = None\n",
    "            else:\n",
    "                sample_idxs = self.rng.choice(len(y),\n",
    "                                     size=math.floor(self.subsample * len(y)),\n",
    "                                     replace=False)\n",
    "                \n",
    "            booster = TreeBooster(X, gradients, hessians, self.max_depth, self.min_child_weight, self.reg_lambda, self.gamma, sample_idxs)\n",
    "            current_predictions += self.learning_rate * booster.predict(X)\n",
    "            self.boosters.append(booster)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame): X = X.values\n",
    "        return self.base_score + np.sum([self.learning_rate * booster.predict(X) for booster in self.boosters], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3   12.0\n",
       "3    151.5   41.3       58.5   16.5\n",
       "4    180.8   10.8       58.4   17.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1   14.0\n",
       "197  177.0    9.3        6.4   14.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   18.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('advertising.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TV         200 non-null    float64\n",
      " 1   Radio      200 non-null    float64\n",
      " 2   Newspaper  200 non-null    float64\n",
      " 3   Sales      200 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.3847068126542923\n",
      "r2 score:  0.9378703321189994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "xgboost_regressor = XGBoostRegressor(learning_rate=0.1, max_depth=3)\n",
    "xgboost_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgboost_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'r2 score: ', r2_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.5058464432638747\n",
      "r2 score:  0.9183606799021481\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,    \n",
    "    learning_rate=0.1,  \n",
    "    max_depth=3  \n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'r2 score: ', r2_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('car_evaluation.csv')\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
